{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "06f2ddX0w2to",
        "colab_type": "code",
        "outputId": "c5b93c11-86ad-4507-bbe0-239dd42bbfec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install unidecode\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import pickle \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Download and unzip files\n",
        "# added example\n",
        "!ls \"/content/drive/My Drive\"\n",
        "!sudo apt-get install unzip\n",
        "!pwd\n",
        "####################################\n",
        "#texts\n",
        "####################################\n",
        "train_x_p = \"/content/drive/My Drive/train_x.p\"\n",
        "train_y_p = \"/content/drive/My Drive/train_y.p\"\n",
        "test_x_p = \"/content/drive/My Drive/test_x.p\"\n",
        "test_y_p = \"/content/drive/My Drive/test_y.p\"\n",
        "\n",
        "train_x = pickle.load( open( train_x_p, \"rb\" ) )\n",
        "train_y = pickle.load( open( train_y_p , \"rb\" ) )\n",
        "test_x = pickle.load( open( test_x_p, \"rb\" ) )\n",
        "test_y = pickle.load( open( test_y_p, \"rb\" ) )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'550 midterm.gdoc'\t\t\t        MS3.txt\n",
            "'594_UML_AT_v2 (2)(9).drawio'\t\t       'New TA Welcome.gdoc'\n",
            " cis530_hw6\t\t\t\t        test_x.p\n",
            "'Colab Notebooks'\t\t\t        test_y.p\n",
            "'Data Science Bowl Test 235ca8 (1).ipynb'       train_x.p\n",
            "'Expense Reimbursement Spreadsheet 2019.xlsx'   train_y.p\n",
            "'Getting started.pdf'\t\t\t       'Untitled document.gdoc'\n",
            " glove.6B.50d.txt\t\t\t       'WKwan Resume Penn (1).docx'\n",
            " MS3.gdoc\t\t\t\t       'WKwan Resume Penn.docx'\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRCpxY5C3V1g",
        "colab_type": "code",
        "outputId": "4c5ce010-4be2-42da-f51d-d1be7f44252d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "nltk.download('popular')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD1SQ8gqn_-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Call on each x of the array \n",
        "def punctuation_removal(x):\n",
        "    temp = \"\"\n",
        "    for i in x:\n",
        "        if i not in string.punctuation:\n",
        "            temp+=i\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lolitJojpBdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Call on each x of the array \n",
        "def lemmatize(x):\n",
        "    temp = \"\"\n",
        "    for i in range(len(x.split())):\n",
        "        lem = lemmatizer.lemmatize(x.split()[i], pos=\"v\")\n",
        "        temp += lem + \" \"\n",
        "    temp = temp.rstrip()\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PP3GSjNvale",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Call on each x of the array\n",
        "def stopword_removal(x):\n",
        "    temp = \"\"\n",
        "    for i in x.split():\n",
        "        if i.lower() not in stopwords.words('english'):\n",
        "            temp += i + \" \"\n",
        "    temp = temp.rstrip()\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpCUVOQQzRNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_processing(X_train):\n",
        "    processed_text = []\n",
        "    for i in X_train:\n",
        "        temp = punctuation_removal(i)\n",
        "        temp = lemmatize(temp)\n",
        "        temp = stopword_removal(temp)\n",
        "        processed_text.append(temp)\n",
        "    return processed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpaJK7NIwSh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "# train_y = labelencoder.fit_transform(train_y)\n",
        "train_y = labelencoder.fit_transform(train_y)\n",
        "test_y = labelencoder.fit_transform(test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZMNsSaCzq4Z",
        "colab_type": "code",
        "outputId": "03897ab0-787f-4760-d6e9-c2de09d0df41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "X_train = text_processing(train_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Drugstore giant Revco DS Inc say Monday agree buy regional chain Big B Inc sweeten takeover value 380 million transaction call Twinsburg Ohiobased Revco buy outstanding share Big B common stock 1725 per share Revcos unsolicited offer 15 per share Big B reject last month excite combination Revco Big B please able bring process fast successful conclusion say Dwayne Hoven president chief executive officer Revco deal combine nations second 10thlargest drug store chain company say Big Bs board directors unanimously approve latest offer recommend Big B shareholders tender share sale Bessemer Alabased Big B mark latest acquisition rapidly consolidate drugstore industry Rite Aid Corp sign agreement month buy West Coast chain Thrifty PayLess Inc 14 billion Thrift Drug Inc unit JC Penney Co Inc agree August buy Fays Inc 285 million Although Big B reject initial offer stock recently trade 16 per share view company would sell Revcos original 15 per share offer Revcos stock trade 125 cents 2950 share New York Stock Exchange Big Bs share 17 4375 cents afternoon trade Nasdaq Revcos financial resources technological expertise market sales capability together grow combine company customer base increase sales potential Among efficiencies combination allow combine company spread cost larger base store Hoven say Big B say work Revco ensure smooth transition Like many regional drugstore chain Big B fight problems accompany burgeon clout manage health care company huge discount retailers hurt deteriorate profit margins sales earn disappoint Wall Street Industry experts say Revco wellplaced capture profit Southeast take advantage Big Bs underused distribution centre close overlap store Georgia Revco able integrate Big B really quickly say Eric Bosshard Midwest ResearchMaxus Group Big Bs profit margins begin tumble last year due difficulty calculate impact lower prescription price pay manage care providers Although invest heaviliy new computer system better track profit margins people familiar company say newly expand distribution centre operate 60 percent capacity Analysts say one Revcos first step assess store overlap especially Georgia Revco operate 180 store Big B 160 store get distribution store together real profit centre Revco say John Strauss investment advisory firm Strauss Financial Group Revco also say revise extend tender offer Big B share Nov 15 offer set expire Monday two company also say litigation withdraw haggle term Revco earlier month sign confidentiality agreement Big B take peek book apparently like saw Big B board meet weekend accept new higher offer Revco Details offer immediately know although Eckerd Corp view potential bidder Eckerd decline comment Big B Inc operate 397 units throughout Southeastern United States Revco operate 2202 store 14 contiguous Midwestern Southeastern Eastern state deal Big B see significant acquisition Revco earlier year involve fail transaction Rite Aid two company sign pact Rite Aid buy Revco 18 billion deal collapse regulators express concern union would raise consumer price'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa1qe1eNxHEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_transformer = CountVectorizer(analyzer=text_processing).fit(train_x)\n",
        "text_bow_train = bow_transformer.transform(train_x)\n",
        "text_bow_test = bow_transformer.transform(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-7X5qfoxHl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# model = MultinomialNB()\n",
        "# model = model.fit(text_bow_train, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VByXTh_SBylK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "fcd5981f-913e-468a-df06-46c68dcb629c"
      },
      "source": [
        "# from xgboost import XGBClassifier\n",
        "# model = XGBClassifier()\n",
        "# model.fit(text_bow_train, train_y)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsgbGuxYCjYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "0c3c76de-c49a-4c9f-af2b-762a67c751de"
      },
      "source": [
        "#BASELINE MODEL\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators = 10000)\n",
        "model.fit(text_bow_train, train_y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDzR9-luejH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "03601b98-a0da-4efd-d01a-66ed33ab98d7"
      },
      "source": [
        "# model2 = RandomForestClassifier(n_estimators = 100000)\n",
        "# model2.fit(text_bow_train, train_y)\n",
        "# model2.score(text_bow_train, train_y)\n",
        "# model2.score(text_bow_test, test_y)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-00c9fc9f8205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_bow_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_bow_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_bow_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv6j8xX3BHXH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f0b8a9d-ebcd-41fc-b50c-091b45f25b1e"
      },
      "source": [
        "model.score(text_bow_train, train_y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlz1QIEHBNNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8266c2a2-91f7-4757-dd1c-36fd7d843f7e"
      },
      "source": [
        "model.score(text_bow_test, test_y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R32iQYT_BRTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4053ce2b-2f21-4ade-b703-7a76ca2ed7e7"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions = model.predict(text_bow_test)\n",
        "print(classification_report(test_y,predictions))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.40      0.30        10\n",
            "           1       0.43      0.30      0.35        10\n",
            "           2       0.71      0.50      0.59        10\n",
            "           3       0.45      0.50      0.48        10\n",
            "           4       0.33      0.10      0.15        10\n",
            "           5       0.60      0.30      0.40        10\n",
            "           6       0.30      0.30      0.30        10\n",
            "           7       0.80      0.40      0.53        10\n",
            "           8       0.60      0.30      0.40        10\n",
            "           9       0.40      0.20      0.27        10\n",
            "          10       0.62      1.00      0.77        10\n",
            "          11       0.55      0.60      0.57        10\n",
            "          12       0.50      0.20      0.29        10\n",
            "          13       0.44      0.80      0.57        10\n",
            "          14       0.33      0.30      0.32        10\n",
            "          15       1.00      0.80      0.89        10\n",
            "          16       0.71      0.50      0.59        10\n",
            "          17       0.75      0.30      0.43        10\n",
            "          18       0.40      0.60      0.48        10\n",
            "          19       0.56      0.50      0.53        10\n",
            "          20       0.58      0.70      0.64        10\n",
            "          21       0.73      0.80      0.76        10\n",
            "          22       0.38      0.30      0.33        10\n",
            "          23       0.14      0.10      0.12        10\n",
            "          24       0.42      0.50      0.45        10\n",
            "          25       0.44      0.80      0.57        10\n",
            "          26       0.70      0.70      0.70        10\n",
            "          27       0.62      1.00      0.77        10\n",
            "          28       0.50      0.80      0.62        10\n",
            "          29       0.45      0.50      0.48        10\n",
            "          30       0.40      0.40      0.40        10\n",
            "          31       0.43      0.30      0.35        10\n",
            "          32       0.64      0.70      0.67        10\n",
            "          33       0.60      0.30      0.40        10\n",
            "          34       0.22      0.20      0.21        10\n",
            "          35       0.20      0.10      0.13        10\n",
            "          36       0.75      0.60      0.67        10\n",
            "          37       0.59      1.00      0.74        10\n",
            "          38       0.60      0.60      0.60        10\n",
            "          39       0.62      0.50      0.56        10\n",
            "          40       0.55      0.60      0.57        10\n",
            "          41       0.33      0.20      0.25        10\n",
            "          42       0.36      0.50      0.42        10\n",
            "          43       0.00      0.00      0.00        10\n",
            "          44       0.36      0.50      0.42        10\n",
            "          45       0.58      0.70      0.64        10\n",
            "          46       0.56      0.90      0.69        10\n",
            "          47       0.33      0.60      0.43        10\n",
            "          48       0.44      0.40      0.42        10\n",
            "          49       0.25      0.30      0.27        10\n",
            "\n",
            "    accuracy                           0.49       500\n",
            "   macro avg       0.49      0.49      0.47       500\n",
            "weighted avg       0.49      0.49      0.47       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiMTkIekBl28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}