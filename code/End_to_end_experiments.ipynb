{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j8YjS5TejSiB",
    "outputId": "9cfa37fa-b7a0-4085-819f-b3eedfa560b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "7rWryW65eV5Y",
    "outputId": "365c334d-b630-4cd6-ed9c-3e2bc12cf5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.42)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDyJR1DyiOvy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    XLNetConfig, \n",
    "    XLNetForSequenceClassification, \n",
    "    XLNetTokenizer,\n",
    "    XLMConfig, \n",
    "    XLMForSequenceClassification, \n",
    "    XLMTokenizer,\n",
    "    RobertaConfig, \n",
    "    RobertaForSequenceClassification, \n",
    "    RobertaTokenizer,\n",
    "    DistilBertConfig, \n",
    "    DistilBertForSequenceClassification, \n",
    "    DistilBertTokenizer,\n",
    "    AlbertConfig, \n",
    "    AlbertForSequenceClassification, \n",
    "    AlbertTokenizer,\n",
    "    XLMRobertaConfig, \n",
    "    XLMRobertaForSequenceClassification, \n",
    "    XLMRobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I82-yQFQJeTr"
   },
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    \"xlnet\": (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    \"xlm\": (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),\n",
    "    \"distilbert\": (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer),\n",
    "    \"albert\": (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer),\n",
    "    \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer),\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLatveM7J1o5"
   },
   "outputs": [],
   "source": [
    "## Model setup\n",
    "model_type = 'bert'\n",
    "model_name = 'bert-large-cased'\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name, do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pN-sWy7XUVe3"
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath global variables\n",
    "ROOT = \"../\"\n",
    "DATA_PATH = ROOT + 'data/'\n",
    "OUTPUT_PATH = ROOT + 'output/'\n",
    "DATASETS_PATH = DATA_PATH + 'datasets/'\n",
    "MODELS_PATH = OUTPUT_PATH + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99uCftDRiOwB"
   },
   "outputs": [],
   "source": [
    "def get_data(subset='train'):\n",
    "    texts = []\n",
    "    for root, folders, files in os.walk(DATASETS_PATH + 'C50/C50{}'.format(subset)):\n",
    "        if len(files) == 0:\n",
    "            continue\n",
    "\n",
    "        author = root.split('/')[-1]\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    texts.append({\n",
    "                        'author': author,\n",
    "                        'text': f.read(),\n",
    "\n",
    "                    })\n",
    "    df = pd.DataFrame(texts)\n",
    "    unique_authors = sorted(df['author'].unique())\n",
    "    num_authors = len(unique_authors)\n",
    "    author_to_id = { unique_authors[i]: i for i in range(num_authors) }\n",
    "    df = df.assign(author_id=df['author'].apply(lambda a: author_to_id[a]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLNmwPLyiOwE"
   },
   "outputs": [],
   "source": [
    "def get_encodings(texts):\n",
    "    token_ids = []\n",
    "    attention_masks = []\n",
    "    for text in texts:\n",
    "        token_id = tokenizer.encode(text, \n",
    "                                    add_special_tokens=True, \n",
    "                                    max_length=MAX_LEN,\n",
    "                                    pad_to_max_length=True)\n",
    "        token_ids.append(token_id)\n",
    "    return token_ids\n",
    "\n",
    "\n",
    "\n",
    "def get_attention_masks(padded_encodings):\n",
    "    attention_masks = []\n",
    "    for encoding in padded_encodings:\n",
    "        attention_mask = [int(token_id > 0) for token_id in encoding]\n",
    "        attention_masks.append(attention_mask)\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qz4sWj33nTz"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(DATASETS_PATH + 'reuters50_train.pkl')\n",
    "test_df = pd.read_pickle(DATASETS_PATH + 'reuters50_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWjVYsuPvaVW"
   },
   "outputs": [],
   "source": [
    "train_encodings = get_encodings(train_df.text.values)\n",
    "train_attention_masks = get_attention_masks(train_encodings)\n",
    "\n",
    "test_encodings = get_encodings(test_df.text.values)\n",
    "test_attention_masks = get_attention_masks(test_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BfjMuKciOwK"
   },
   "outputs": [],
   "source": [
    "train_input_ids = torch.tensor(train_encodings)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "train_labels = torch.tensor(train_df.author_id.values)\n",
    "\n",
    "\n",
    "test_input_ids = torch.tensor(test_encodings)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_labels = torch.tensor(test_df.author_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKetuFLPiOwN"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCk5nwZyiOwR"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def get_confusion_matrix(preds, labels):\n",
    "  \"\"\"\n",
    "  Rows = true labels\n",
    "  Columns = classified labels\n",
    "  \"\"\"\n",
    "    confusion_matrix = np.zeros((50, 50))\n",
    "    preds = np.argmax(preds, axis=1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    for i, label in enumerate(labels):\n",
    "        pred = preds[i]\n",
    "        confusion_matrix[label][pred] += 1\n",
    "    eturn confusion_matrix\n",
    "\n",
    "def parse_confusion_matrix(confusion_matrix):\n",
    "  \"\"\"\n",
    "  Rows = labels\n",
    "  Col0 = tp\n",
    "  Col1 = fp\n",
    "  Col2 = fn\n",
    "  Col3 = tn\n",
    "  \"\"\"\n",
    "    parsed_confusion_matrix = np.zeros((50, 4))\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        tp = confusion_matrix[i][i]\n",
    "        fp = confusion_matrix[:, i].sum() - tp\n",
    "        fn = confusion_matrix[i, :].sum() - tp \n",
    "        tn = confusion_matrix.sum() - tp - fp - fn\n",
    "        \n",
    "        parsed_confusion_matrix[i][0] = tp\n",
    "        parsed_confusion_matrix[i][1] = fp\n",
    "        parsed_confusion_matrix[i][2] = fn\n",
    "        parsed_confusion_matrix[i][3] = tn\n",
    "    return parsed_confusion_matrix\n",
    "\n",
    "def calculate_avg_precision(parsed_confusion_matrix):\n",
    "  \"\"\"\n",
    "  Calculates macro average precision\n",
    "  \"\"\"\n",
    "    total_precision = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, fp, _, _ = parsed_confusion_matrix[i]\n",
    "        precision = tp / (tp + fp)\n",
    "        if not np.isnan(precision):\n",
    "            total_precision += precision\n",
    "    return total_precision / num_classes\n",
    "\n",
    "def calculate_avg_recall(parsed_confusion_matrix):\n",
    "  \"\"\"\n",
    "  Calculates macro average recall\n",
    "  \"\"\"\n",
    "    total_recall = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, _, fn, _ = parsed_confusion_matrix[i]\n",
    "        recall = tp / (tp + fn)\n",
    "        if not np.isnan(recall):\n",
    "            total_recall += recall\n",
    "    return total_recall / num_classes\n",
    "\n",
    "def calculate_avg_f1(parsed_confusion_matrix):\n",
    "  \"\"\"\n",
    "  Calculates macro average f1 score\n",
    "  \"\"\"\n",
    "    total_f1 = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, fp, fn, _ = parsed_confusion_matrix[i]\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2*((precision * recall) / (precision + recall))\n",
    "        if not np.isnan(f1):\n",
    "            total_f1 += f1\n",
    "    return total_f1 / num_classes\n",
    "\n",
    "def calculate_avg_mcc(parsed_confusion_matrix):\n",
    "  \"\"\"\n",
    "  Calculates macro average Matthews correlation coefficient\n",
    "  \"\"\"\n",
    "    total_mcc = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, fp, fn, tn = parsed_confusion_matrix[i]\n",
    "        mcc = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "        if not np.isnan(mcc):\n",
    "            total_mcc += mcc\n",
    "    return total_mcc / num_classes\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqVkEgIjkPg5"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_xbow_p = DATA_PATH + \"text_bow_train.p\"\n",
    "test_xbow_p = DATA_PATH + \"text_bow_test.p\"\n",
    "train_bow = pickle.load( open( train_xbow_p, \"rb\" ) )\n",
    "test_bow = pickle.load( open( test_xbow_p, \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY01HB01lbvd"
   },
   "outputs": [],
   "source": [
    "train_bow = torch.tensor(train_bow.todense(), dtype = torch.double, device = device)\n",
    "test_bow = torch.tensor(test_bow.todense(), dtype = torch.double, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYowUQaBrzmW"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \"\"\"\n",
    "    End to end neural net that combines with BERT model\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_model):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(1071, 700)\n",
    "        self.output = nn.Linear(700, 50)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(700)\n",
    "        self.bert = bert_model\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sD1c-osFT7Ek",
    "outputId": "c03f7e84-3280-4275-8649-6f69996fde07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Instantiate a brand new bert model\n",
    "\n",
    "config = config_class.from_pretrained(model_name, num_labels=50, output_hidden_states=True)\n",
    "bert = model_class.from_pretrained(model_name, config=config)\n",
    "\n",
    "# bert_filename = 'bert_bert-base-cased_max-length=128.pth'\n",
    "# bert.load_state_dict(torch.load(ROOT + '/models/' + model_filename))\n",
    "bert.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktS-64KIk1Sz"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 4\n",
    "lr = 1e-3\n",
    "eps = 1e-8\n",
    "epochs = 20\n",
    "weight_decay = 2e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3jApuPL9wEBc",
    "outputId": "d7e5ccd7-53b3-483d-f0fb-2b6e7eae3f9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (hidden1): Linear(in_features=1071, out_features=700, bias=True)\n",
       "  (output): Linear(in_features=700, out_features=50, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batchnorm1): BatchNorm1d(700, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bert): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 1024)\n",
       "        (token_type_embeddings): Embedding(2, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (18): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (19): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (20): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (21): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (22): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (23): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=1024, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet = NeuralNet(bert)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(nnet.parameters(), lr=lr, eps=eps, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.7)\n",
    "\n",
    "nnet.double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZcE9jdGURxM"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_input_ids, train_masks, train_bow, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_masks, test_bow, test_labels)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5X18U6JFw3ei",
    "outputId": "f22b4c50-fbef-46d6-c398-f7150bf41771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:02.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:02:23.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:02:32.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:02:50.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:02:59.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:03:07.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:03:16.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:03:25.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:03:34.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:03:43.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:03:52.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:04:01.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:04:10.\n",
      "Epoch: [1/20], elapsed: 0:04:11, loss: 3.0923911159313233, acc: 0.2348888888888889\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test :- elapsed: 0:00:25, loss: 1.4959390758968705, acc: 0.672\n",
      "Precision: 0.7111091188242216, Recall: 0.6719999999999999, F1: 0.6612868577877257, MCC: 0.6703841613742401\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:02.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:02:23.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:02:32.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:02:50.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:02:59.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:03:07.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:03:16.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:03:25.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:03:34.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:03:43.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:03:52.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:04:01.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:04:10.\n",
      "Epoch: [2/20], elapsed: 0:04:11, loss: 1.3222600166688214, acc: 0.6482222222222223\n",
      "\n",
      "Running Validation...\n",
      "Test :- elapsed: 0:00:25, loss: 0.7846184706030653, acc: 0.79\n",
      "Precision: 0.8261415424960313, Recall: 0.7899999999999995, F1: 0.7809796351967233, MCC: 0.7900565836506659\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:02.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:02:23.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:02:32.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:02:50.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:02:59.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:03:07.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:03:16.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:03:25.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:03:34.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:03:43.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:03:52.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:04:01.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:04:10.\n",
      "Epoch: [3/20], elapsed: 0:04:11, loss: 0.7707595299160435, acc: 0.786\n",
      "\n",
      "Running Validation...\n",
      "Test :- elapsed: 0:00:25, loss: 0.6210600457841514, acc: 0.846\n",
      "Precision: 0.8619937839937839, Recall: 0.8459999999999996, F1: 0.842507737898571, MCC: 0.8452591163684379\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:02.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:02:23.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:02:32.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:02:50.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:02:59.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:03:08.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:03:17.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:03:25.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:03:34.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:03:43.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:03:52.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:04:01.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:04:10.\n",
      "Epoch: [4/20], elapsed: 0:04:11, loss: 0.5641494462039077, acc: 0.8495555555555555\n",
      "\n",
      "Running Validation...\n",
      "Test :- elapsed: 0:00:25, loss: 0.5480220959044029, acc: 0.866\n",
      "Precision: 0.881752858252858, Recall: 0.8659999999999995, F1: 0.864518049657974, MCC: 0.8666119743687405\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:03.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:02:23.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:02:32.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:02:50.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:02:59.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:03:08.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:03:17.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:03:26.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:03:34.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:03:43.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:03:52.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:04:01.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:04:10.\n",
      "Epoch: [5/20], elapsed: 0:04:11, loss: 0.48538557222600887, acc: 0.8691111111111111\n",
      "\n",
      "Running Validation...\n",
      "Test :- elapsed: 0:00:25, loss: 0.54262369543596, acc: 0.864\n",
      "Precision: 0.8794408924408921, Recall: 0.8639999999999998, F1: 0.8623926695042592, MCC: 0.8644176742460263\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:03.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:02:23.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:02:32.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:02:50.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:02:59.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:03:08.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:03:17.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:03:25.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:03:34.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:03:43.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:03:52.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:04:01.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:04:10.\n",
      "Epoch: [6/20], elapsed: 0:04:11, loss: 0.45817785149312135, acc: 0.8848888888888888\n",
      "\n",
      "Running Validation...\n",
      "Test :- elapsed: 0:00:25, loss: 0.5189532417856486, acc: 0.87\n",
      "Precision: 0.8803814518814516, Recall: 0.8699999999999997, F1: 0.8678974341418139, MCC: 0.8690276530433368\n",
      "\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:02.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n",
      "  Batch   640  of  1,125.    Elapsed: 0:02:23.\n",
      "  Batch   680  of  1,125.    Elapsed: 0:02:32.\n",
      "  Batch   720  of  1,125.    Elapsed: 0:02:41.\n",
      "  Batch   760  of  1,125.    Elapsed: 0:02:50.\n",
      "  Batch   800  of  1,125.    Elapsed: 0:02:59.\n",
      "  Batch   840  of  1,125.    Elapsed: 0:03:08.\n",
      "  Batch   880  of  1,125.    Elapsed: 0:03:16.\n",
      "  Batch   920  of  1,125.    Elapsed: 0:03:25.\n",
      "  Batch   960  of  1,125.    Elapsed: 0:03:34.\n",
      "  Batch 1,000  of  1,125.    Elapsed: 0:03:43.\n",
      "  Batch 1,040  of  1,125.    Elapsed: 0:03:52.\n",
      "  Batch 1,080  of  1,125.    Elapsed: 0:04:01.\n",
      "  Batch 1,120  of  1,125.    Elapsed: 0:04:10.\n",
      "Epoch: [7/20], elapsed: 0:04:11, loss: 0.43077899366159716, acc: 0.8897777777777778\n",
      "\n",
      "Running Validation...\n",
      "Test :- elapsed: 0:00:25, loss: 0.5023674653561672, acc: 0.872\n",
      "Precision: 0.8834375069375068, Recall: 0.8719999999999996, F1: 0.8704308411111477, MCC: 0.8715678312323857\n",
      "\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,125.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,125.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,125.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,125.    Elapsed: 0:00:45.\n",
      "  Batch   240  of  1,125.    Elapsed: 0:00:54.\n",
      "  Batch   280  of  1,125.    Elapsed: 0:01:02.\n",
      "  Batch   320  of  1,125.    Elapsed: 0:01:11.\n",
      "  Batch   360  of  1,125.    Elapsed: 0:01:20.\n",
      "  Batch   400  of  1,125.    Elapsed: 0:01:29.\n",
      "  Batch   440  of  1,125.    Elapsed: 0:01:38.\n",
      "  Batch   480  of  1,125.    Elapsed: 0:01:47.\n",
      "  Batch   520  of  1,125.    Elapsed: 0:01:56.\n",
      "  Batch   560  of  1,125.    Elapsed: 0:02:05.\n",
      "  Batch   600  of  1,125.    Elapsed: 0:02:14.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               Training\n",
    "# ========================================\n",
    "\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    nnet.train()\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        input_ids, input_masks, bow, labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Run input IDs and masks through BERT first to get embeddings\n",
    "        # then combine with BOW to run through rest of nnet model\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = nnet.bert(input_ids, attention_mask=input_masks)[1][0]\n",
    "        embeddings = embeddings.mean(dim=1).double() \n",
    "\n",
    "        features_comb = torch.cat((embeddings, bow), dim=1)\n",
    "\n",
    "        outputs = nnet(features_comb)\n",
    "        vals, inds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        train_loss += loss\n",
    "\n",
    "        acc = torch.eq(inds, labels).sum().item() / labels.shape[0]\n",
    "        train_acc += acc\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(nnet.parameters(), 1.0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    elapsed = format_time(time.time() - t0)\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    avg_train_acc = train_acc / len(train_dataloader)\n",
    "    train_loss_values.append(avg_train_loss)\n",
    "    print(f\"Epoch: [{epoch}/{epochs}], elapsed: {elapsed}, loss: {avg_train_loss}, acc: {avg_train_acc}\")\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    nnet.eval()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    confusion_matrix = torch.zeros((50, 50))\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "\n",
    "        input_ids, input_masks, bow, labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = nnet.bert(input_ids, attention_mask=input_masks)[1][0]\n",
    "            embeddings = embeddings.mean(dim=1).double() \n",
    "\n",
    "            features_comb = torch.cat((embeddings, bow), dim=1)\n",
    "\n",
    "            outputs = nnet(features_comb)\n",
    "            vals, inds = torch.max(outputs, dim=1)\n",
    "        \n",
    "            loss = loss_function(outputs, labels)\n",
    "            test_loss += loss\n",
    "\n",
    "            acc = torch.eq(inds, labels).sum().item() / labels.shape[0]\n",
    "            test_acc += acc\n",
    "\n",
    "            preds = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            tmp_confusion_matrix = get_confusion_matrix(preds, labels)\n",
    "            confusion_matrix += tmp_confusion_matrix\n",
    "\n",
    "    elapsed = format_time(time.time() - t0)\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_acc = test_acc / len(test_dataloader)\n",
    "    test_loss_values.append(avg_test_loss)\n",
    "\n",
    "    parsed_confusion_matrix = parse_confusion_matrix(confusion_matrix)\n",
    "    avg_precision = calculate_avg_precision(parsed_confusion_matrix)\n",
    "    avg_recall = calculate_avg_recall(parsed_confusion_matrix)\n",
    "    avg_f1 = calculate_avg_f1(parsed_confusion_matrix)\n",
    "    avg_mcc = calculate_avg_mcc(parsed_confusion_matrix)\n",
    "\n",
    "    print(f\"Test :- elapsed: {elapsed}, loss: {avg_test_loss}, acc: {avg_test_acc}\")\n",
    "    print(f\"Precision: {avg_precision}, Recall: {avg_recall}, F1: {avg_f1}, MCC: {avg_mcc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdExcdc64gz8"
   },
   "outputs": [],
   "source": [
    "model_filename = f'END_TO_END_{model_type}_{model_name}_max-length={MAX_LEN}.pth'\n",
    "torch.save(nnet.state_dict(), MODELS_PATH + model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rZKTuRzSFqH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT+BOW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
